{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomaA2000/face_detecting/blob/master/TestFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjU2GlP8T3gt",
        "colab_type": "code",
        "outputId": "5b74c122-6312-4e4a-8af2-5ccbe754ee80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import codecs\n",
        "import math\n",
        "import requests\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import copy\n",
        "from torchvision import transforms\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "from skimage.feature import hog\n",
        "from skimage import data, exposure\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "torch.backends.cuda.deterministic = True\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Выбрать нужный путь до данных\n",
        "dir_name = '/content/drive/My Drive/Data'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-PFIwy-XP1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_size = 256\n",
        "y_size = 256\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.data[0][idx], self.data[1][idx])\n",
        "      \n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((x_size, y_size)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((x_size, y_size)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dir = os.path.join(dir_name, 'train')\n",
        "val_dir = os.path.join(dir_name, 'val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avSzHmhJBgna",
        "colab_type": "code",
        "outputId": "618f89a4-b8bd-4dc0-ba09-f441086d8c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(os.listdir('/content/drive/My Drive/Data/train'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['answers', 'pic0.npy', 'pic1.npy', 'pic2.npy', 'pic3.npy', 'pic4.npy', 'pic8.npy', 'pic5.npy', 'pic9.npy', 'pic6.npy', 'pic15.npy', 'pic10.npy', 'pic7.npy', 'pic11.npy', 'pic16.npy', 'pic22.npy', 'pic12.npy', 'pic17.npy', 'pic23.npy', 'pic13.npy', 'pic24.npy', 'pic18.npy', 'pic14.npy', 'pic25.npy', 'pic19.npy', 'pic26.npy', 'pic38.npy', 'pic20.npy', 'pic27.npy', 'pic21.npy', 'pic39.npy', 'pic28.npy', 'pic40.npy', 'pic41.npy', 'pic29.npy', 'pic46.npy', 'pic42.npy', 'pic30.npy', 'pic47.npy', 'pic43.npy', 'pic31.npy', 'pic48.npy', 'pic32.npy', 'pic44.npy', 'pic49.npy', 'pic33.npy', 'pic45.npy', 'pic50.npy', 'pic34.npy', 'pic55.npy', 'pic51.npy', 'pic35.npy', 'pic56.npy', 'pic52.npy', 'pic36.npy', 'pic57.npy', 'pic53.npy', 'pic37.npy', 'pic58.npy', 'pic54.npy', 'pic62.npy', 'pic59.npy', 'pic76.npy', 'pic63.npy', 'pic60.npy', 'pic77.npy', 'pic61.npy', 'pic64.npy', 'pic78.npy', 'pic65.npy', 'pic79.npy', 'pic66.npy', 'pic86.npy', 'pic80.npy', 'pic67.npy', 'pic87.npy', 'pic81.npy', 'pic68.npy', 'pic88.npy', 'pic82.npy', 'pic69.npy', 'pic89.npy', 'pic83.npy', 'pic70.npy', 'pic90.npy', 'pic84.npy', 'pic71.npy', 'pic85.npy', 'pic91.npy', 'pic72.npy', 'pic92.npy', 'pic105.npy', 'pic93.npy', 'pic73.npy', 'pic106.npy', 'pic94.npy', 'pic74.npy', 'pic107.npy', 'pic95.npy', 'pic75.npy', 'pic108.npy', 'pic110.npy', 'pic96.npy', 'pic109.npy', 'pic111.npy', 'pic97.npy', 'pic112.npy', 'pic121.npy', 'pic98.npy', 'pic113.npy', 'pic122.npy', 'pic99.npy', 'pic114.npy', 'pic123.npy', 'pic100.npy', 'pic115.npy', 'pic124.npy', 'pic101.npy', 'pic116.npy', 'pic102.npy', 'pic117.npy', 'pic103.npy', 'pic125.npy', 'pic118.npy', 'pic104.npy', 'pic126.npy', 'pic119.npy', 'pic128.npy', 'pic127.npy', 'pic148.npy', 'pic120.npy', 'pic129.npy', 'pic149.npy', 'pic130.npy', 'pic150.npy', 'pic152.npy', 'pic131.npy', 'pic151.npy', 'pic153.npy', 'pic132.npy', 'pic154.npy', 'pic156.npy', 'pic133.npy', 'pic155.npy', 'pic157.npy', 'pic134.npy', 'pic163.npy', 'pic158.npy', 'pic135.npy', 'pic164.npy', 'pic159.npy', 'pic136.npy', 'pic165.npy', 'pic160.npy', 'pic137.npy', 'pic166.npy', 'pic161.npy', 'pic138.npy', 'pic167.npy', 'pic162.npy', 'pic139.npy', 'pic168.npy', 'pic140.npy', 'pic170.npy', 'pic169.npy', 'pic187.npy', 'pic141.npy', 'pic171.npy', 'pic188.npy', 'pic142.npy', 'pic172.npy', 'pic189.npy', 'pic143.npy', 'pic173.npy', 'pic190.npy', 'pic144.npy', 'pic174.npy', 'pic191.npy', 'pic145.npy', 'pic175.npy', 'pic192.npy', 'pic176.npy', 'pic146.npy', 'pic193.npy', 'pic177.npy', 'pic147.npy', 'pic194.npy', 'pic178.npy', 'pic195.npy', 'pic200.npy', 'pic179.npy', 'pic196.npy', 'pic201.npy', 'pic180.npy', 'pic197.npy', 'pic202.npy', 'pic181.npy', 'pic198.npy', 'pic203.npy', 'pic182.npy', 'pic199.npy', 'pic204.npy', 'pic183.npy', 'pic214.npy', 'pic205.npy', 'pic184.npy', 'pic215.npy', 'pic206.npy', 'pic185.npy', 'pic216.npy', 'pic207.npy', 'pic186.npy', 'pic217.npy', 'pic208.npy', 'pic218.npy', 'pic229.npy', 'pic209.npy', 'pic219.npy', 'pic230.npy', 'pic210.npy', 'pic220.npy', 'pic231.npy', 'pic211.npy', 'pic221.npy', 'pic232.npy', 'pic212.npy', 'pic222.npy', 'pic233.npy', 'pic213.npy', 'pic223.npy', 'pic234.npy', 'pic240.npy', 'pic224.npy', 'pic235.npy', 'pic241.npy', 'pic225.npy', 'pic236.npy', 'pic242.npy', 'pic226.npy', 'pic237.npy', 'pic243.npy', 'pic227.npy', 'pic238.npy', 'pic244.npy', 'pic228.npy', 'pic239.npy', 'pic258.npy', 'pic245.npy', 'pic246.npy', 'pic273.npy', 'pic259.npy', 'pic247.npy', 'pic274.npy', 'pic260.npy', 'pic248.npy', 'pic275.npy', 'pic261.npy', 'pic249.npy', 'pic276.npy', 'pic262.npy', 'pic250.npy', 'pic277.npy', 'pic263.npy', 'pic251.npy', 'pic278.npy', 'pic264.npy', 'pic252.npy', 'pic279.npy', 'pic265.npy', 'pic253.npy', 'pic280.npy', 'pic266.npy', 'pic254.npy', 'pic267.npy', 'pic281.npy', 'pic255.npy', 'pic282.npy', 'pic268.npy', 'pic256.npy', 'pic269.npy', 'pic257.npy', 'pic283.npy', 'pic270.npy', 'pic284.npy', 'pic288.npy', 'pic271.npy', 'pic285.npy', 'pic289.npy', 'pic272.npy', 'pic286.npy', 'pic290.npy', 'pic287.npy', 'pic310.npy', 'pic291.npy', 'pic323.npy', 'pic311.npy', 'pic292.npy', 'pic324.npy', 'pic312.npy', 'pic293.npy', 'pic325.npy', 'pic313.npy', 'pic294.npy', 'pic326.npy', 'pic314.npy', 'pic295.npy', 'pic327.npy', 'pic315.npy', 'pic296.npy', 'pic328.npy', 'pic316.npy', 'pic297.npy', 'pic329.npy', 'pic317.npy', 'pic298.npy', 'pic330.npy', 'pic318.npy', 'pic299.npy', 'pic331.npy', 'pic319.npy', 'pic300.npy', 'pic332.npy', 'pic301.npy', 'pic320.npy', 'pic333.npy', 'pic302.npy', 'pic321.npy', 'pic334.npy', 'pic303.npy', 'pic322.npy', 'pic335.npy', 'pic304.npy', 'pic336.npy', 'pic343.npy', 'pic305.npy', 'pic337.npy', 'pic344.npy', 'pic306.npy', 'pic338.npy', 'pic345.npy', 'pic307.npy', 'pic339.npy', 'pic346.npy', 'pic308.npy', 'pic340.npy', 'pic347.npy', 'pic309.npy', 'pic341.npy', 'pic348.npy', 'pic365.npy', 'pic342.npy', 'pic349.npy', 'pic366.npy', 'pic350.npy', 'pic387.npy', 'pic367.npy', 'pic351.npy', 'pic388.npy', 'pic368.npy', 'pic352.npy', 'pic389.npy', 'pic369.npy', 'pic353.npy', 'pic390.npy', 'pic370.npy', 'pic354.npy', 'pic391.npy', 'pic371.npy', 'pic355.npy', 'pic392.npy', 'pic372.npy', 'pic356.npy', 'pic393.npy', 'pic373.npy', 'pic357.npy', 'pic394.npy', 'pic374.npy', 'pic358.npy', 'pic395.npy', 'pic375.npy', 'pic359.npy', 'pic396.npy', 'pic376.npy', 'pic360.npy', 'pic377.npy', 'pic397.npy', 'pic361.npy', 'pic378.npy', 'pic398.npy', 'pic362.npy', 'pic379.npy', 'pic399.npy', 'pic363.npy', 'pic380.npy', 'pic400.npy', 'pic364.npy', 'pic381.npy', 'pic401.npy', 'pic420.npy', 'pic382.npy', 'pic402.npy', 'pic421.npy', 'pic383.npy', 'pic403.npy', 'pic384.npy', 'pic422.npy', 'pic404.npy', 'pic385.npy', 'pic423.npy', 'pic405.npy', 'pic386.npy', 'pic424.npy', 'pic406.npy', 'pic442.npy', 'pic425.npy', 'pic407.npy', 'pic443.npy', 'pic408.npy', 'pic444.npy', 'pic426.npy', 'pic409.npy', 'pic445.npy', 'pic427.npy', 'pic410.npy', 'pic446.npy', 'pic428.npy', 'pic411.npy', 'pic447.npy', 'pic429.npy', 'pic412.npy', 'pic448.npy', 'pic413.npy', 'pic430.npy', 'pic449.npy', 'pic414.npy', 'pic431.npy', 'pic450.npy', 'pic415.npy', 'pic432.npy', 'pic451.npy', 'pic433.npy', 'pic416.npy', 'pic452.npy', 'pic434.npy', 'pic417.npy', 'pic453.npy', 'pic418.npy', 'pic435.npy', 'pic454.npy', 'pic419.npy', 'pic436.npy', 'pic455.npy', 'pic464.npy', 'pic437.npy', 'pic456.npy', 'pic465.npy', 'pic438.npy', 'pic457.npy', 'pic466.npy', 'pic439.npy', 'pic458.npy', 'pic467.npy', 'pic440.npy', 'pic459.npy', 'pic468.npy', 'pic441.npy', 'pic460.npy', 'pic469.npy', 'pic461.npy', 'pic486.npy', 'pic470.npy', 'pic462.npy', 'pic487.npy', 'pic471.npy', 'pic463.npy', 'pic488.npy', 'pic472.npy', 'pic489.npy', 'pic509.npy', 'pic473.npy', 'pic490.npy', 'pic510.npy', 'pic474.npy', 'pic491.npy', 'pic511.npy', 'pic475.npy', 'pic492.npy', 'pic512.npy', 'pic476.npy', 'pic493.npy', 'pic513.npy', 'pic477.npy', 'pic494.npy', 'pic514.npy', 'pic478.npy', 'pic495.npy', 'pic515.npy', 'pic479.npy', 'pic496.npy', 'pic516.npy', 'pic480.npy', 'pic497.npy', 'pic517.npy', 'pic481.npy', 'pic498.npy', 'pic518.npy', 'pic482.npy', 'pic499.npy', 'pic519.npy', 'pic483.npy', 'pic500.npy', 'pic520.npy', 'pic484.npy', 'pic501.npy', 'pic521.npy', 'pic485.npy', 'pic502.npy', 'pic522.npy', 'pic503.npy', 'pic531.npy', 'pic523.npy', 'pic504.npy', 'pic532.npy', 'pic524.npy', 'pic505.npy', 'pic533.npy', 'pic525.npy', 'pic506.npy', 'pic534.npy', 'pic526.npy', 'pic535.npy', 'pic507.npy', 'pic527.npy', 'pic536.npy', 'pic508.npy', 'pic528.npy', 'pic537.npy', 'pic554.npy', 'pic529.npy', 'pic538.npy', 'pic555.npy', 'pic530.npy', 'pic539.npy', 'pic556.npy', 'pic576.npy', 'pic540.npy', 'pic557.npy', 'pic577.npy', 'pic541.npy', 'pic558.npy', 'pic578.npy', 'pic542.npy', 'pic559.npy', 'pic579.npy', 'pic543.npy', 'pic560.npy', 'pic580.npy', 'pic544.npy', 'pic561.npy', 'pic581.npy', 'pic545.npy', 'pic562.npy', 'pic582.npy', 'pic546.npy', 'pic563.npy', 'pic583.npy', 'pic547.npy', 'pic564.npy', 'pic584.npy', 'pic548.npy', 'pic565.npy', 'pic585.npy', 'pic549.npy', 'pic566.npy', 'pic586.npy', 'pic550.npy', 'pic567.npy', 'pic587.npy', 'pic551.npy', 'pic568.npy', 'pic588.npy', 'pic552.npy', 'pic569.npy', 'pic589.npy', 'pic553.npy', 'pic570.npy', 'pic590.npy', 'pic599.npy', 'pic571.npy', 'pic591.npy', 'pic600.npy', 'pic572.npy', 'pic592.npy', 'pic601.npy', 'pic573.npy', 'pic593.npy', 'pic602.npy', 'pic574.npy', 'pic594.npy', 'pic603.npy', 'pic575.npy', 'pic595.npy', 'pic604.npy', 'pic621.npy', 'pic596.npy', 'pic605.npy', 'pic622.npy', 'pic597.npy', 'pic606.npy', 'pic623.npy', 'pic598.npy', 'pic607.npy', 'pic624.npy', 'pic644.npy', 'pic608.npy', 'pic625.npy', 'pic645.npy', 'pic609.npy', 'pic626.npy', 'pic646.npy', 'pic610.npy', 'pic627.npy', 'pic647.npy', 'pic611.npy', 'pic628.npy', 'pic648.npy', 'pic612.npy', 'pic629.npy', 'pic649.npy', 'pic613.npy', 'pic630.npy', 'pic650.npy', 'pic614.npy', 'pic631.npy', 'pic651.npy', 'pic615.npy', 'pic632.npy', 'pic652.npy', 'pic616.npy', 'pic633.npy', 'pic653.npy', 'pic617.npy', 'pic634.npy', 'pic654.npy', 'pic618.npy', 'pic635.npy', 'pic655.npy', 'pic619.npy', 'pic636.npy', 'pic656.npy', 'pic620.npy', 'pic637.npy', 'pic657.npy', 'pic666.npy', 'pic638.npy', 'pic658.npy', 'pic667.npy', 'pic639.npy', 'pic659.npy', 'pic668.npy', 'pic640.npy', 'pic660.npy', 'pic669.npy', 'pic641.npy', 'pic661.npy', 'pic670.npy', 'pic642.npy', 'pic662.npy', 'pic671.npy', 'pic643.npy', 'pic663.npy', 'pic672.npy', 'pic689.npy', 'pic664.npy', 'pic673.npy', 'pic690.npy', 'pic665.npy', 'pic674.npy', 'pic691.npy', 'pic675.npy', 'pic692.npy', 'pic676.npy', 'pic693.npy', 'pic677.npy', 'pic694.npy', 'pic678.npy', 'pic695.npy', 'pic679.npy', 'pic696.npy', 'pic680.npy', 'pic697.npy', 'pic681.npy', 'pic698.npy', 'pic682.npy', 'pic699.npy', 'pic683.npy', 'pic700.npy', 'pic684.npy', 'pic701.npy', 'pic685.npy', 'pic702.npy', 'pic686.npy', 'pic703.npy', 'pic687.npy', 'pic704.npy', 'pic688.npy', 'pic705.npy', 'pic706.npy', 'pic707.npy', 'pic708.npy', 'pic709.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTCC_TJniV1",
        "colab_type": "code",
        "outputId": "3ada86e9-9715-4857-eec2-64585edf46cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def arr_maker(data_dir, size, transforms_data):\n",
        "    answers = []\n",
        "    pics = []\n",
        "    for idx in tqdm(range(size)):\n",
        "      pics.append(transforms_data(Image.fromarray(np.load(os.path.join(data_dir, \"pic\" + str(idx) + '.npy')))))\n",
        "      answers.append(transforms_data(Image.fromarray(np.load(os.path.join(data_dir, 'answers', 'ans' + str(idx) + '.npy')))))\n",
        "    return (pics, answers)\n",
        "\n",
        "train_dataset = Dataset(arr_maker(train_dir, 710, train_transforms))\n",
        "val_dataset = Dataset(arr_maker(val_dir, 142, val_transforms))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 305/710 [06:20<08:27,  1.25s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7V7UX3scsvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Подбираемые параметры\n",
        "#Если не указаны границы пожно увеличивать пока не упадет CUDA\n",
        "size = 19\n",
        "koef = 0.8\n",
        "#^ 0 - 10 ^# \n",
        "batch_size = 16\n",
        "\n",
        "new_name = os.path.join(dir_name, 'results', \"k_\" + str(koef) + \"_s_\" + str(size) + \"_b_\" + str(batch_size) + \"_size_\" + str(x_size) + \"_addinf_maxch=256\")\n",
        "print(new_name)\n",
        "\n",
        "num_work = 8\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_work)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_work)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1dsL7OpULou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir('/content/drive'))\n",
        "os.mkdir(new_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnKunl4UXgou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, loss, optimizer, scheduler, num_epochs, k):\n",
        "    sub_min = 1.\n",
        "    top_model = model\n",
        "    history = [[], []]\n",
        "    history_2 = [[], []]\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                dataloader = train_dataloader\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                dataloader = val_dataloader\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.\n",
        "            sub_max_epoch = 0.\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                labels *= k\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward and backward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    preds = model(inputs)\n",
        "                    sub_max_epoch = max(torch.max(torch.abs((labels - preds))).item(), sub_max_epoch)\n",
        "                    loss_value = loss(preds, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss_value.backward()\n",
        "                        optimizer.step()\n",
        "                        scheduler.step()\n",
        "                        \n",
        "                # statistics\n",
        "                running_loss += loss_value.item()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader)\n",
        "\n",
        "            print('{} Sub max: {:.4f} Loss: {:.4f}'.format(phase, sub_max_epoch, epoch_loss), flush=True)\n",
        "            \n",
        "            if (phase == 'val'):\n",
        "                history[0].append(epoch_loss)\n",
        "                history[1].append(epoch)\n",
        "                print(sub_max_epoch)\n",
        "                fig, graph = plt.subplots(figsize=(13,8))\n",
        "                graph.plot(history[1], history[0], 'o', linestyle='solid')\n",
        "                plt.show()\n",
        "                plt.pause(0.001)\n",
        "                for number in 5, 21, 23:\n",
        "                    print(os.listdir('/content/drive/My Drive/Data'))\n",
        "                    test = train_transforms(Image.fromarray(np.load(os.path.join(val_dir, \"pic\" + str(number) + '.npy')))) \n",
        "                    plt.imshow(test[0]) \n",
        "                    plt.pause(0.001) \n",
        "                    inp = torch.zeros((1, test.shape[0], test.shape[1], test.shape[2])) \n",
        "                    inp[0] = test \n",
        "                    inp = inp.to(device) \n",
        "                    res = model(inp).cpu()[0] \n",
        "                    inp = inp.to('cpu')\n",
        "                    plt.imshow(res.detach().numpy()[0]) \n",
        "                    plt.pause(0.001)\n",
        "                    plt.imshow(val_dataset.__getitem__(number)[1][0]) \n",
        "                    plt.pause(0.001)\n",
        "                    np.save(os.path.join(new_name, \"out_\" + str(epoch) + '-' + str(number)), res.detach().numpy()[0])\n",
        "                    print('ver 1')\n",
        "            if (phase == 'val' and sub_min > sub_max_epoch):\n",
        "                sub_min = sub_max_epoch\n",
        "            \n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache() \n",
        "    return top_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7DuoCBxXoao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FaceNet(torch.nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super(FaceNet, self).__init__()\n",
        "        kernel_size = size\n",
        "        padding = (kernel_size // 2)\n",
        "        self.con1 = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac1 = torch.nn.PReLU()\n",
        "        self.con2 = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac2 = torch.nn.PReLU()\n",
        "        self.con3 = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac3 = torch.nn.PReLU()\n",
        "        self.con4 = torch.nn.Conv2d(in_channels=8, out_channels=64, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac4 = torch.nn.PReLU()\n",
        "        self.con5 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac5 = torch.nn.PReLU()\n",
        "        self.con6 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac6 = torch.nn.PReLU()\n",
        "        self.con7 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac7 = torch.nn.PReLU()\n",
        "        self.con8 = torch.nn.Conv2d(in_channels=64, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac8 = torch.nn.PReLU()\n",
        "        self.con9 = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac9 = torch.nn.PReLU()\n",
        "        self.con10 = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac10 = torch.nn.PReLU()\n",
        "        self.con11 = torch.nn.Conv2d(in_channels=8, out_channels=1, kernel_size=kernel_size, padding=padding)\n",
        "        self.ac11 = torch.nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        self.bn_2d_0 = torch.nn.BatchNorm2d(1)\n",
        "        self.bn_2d_1 = torch.nn.BatchNorm2d(8)\n",
        "        self.bn_2d_2 = torch.nn.BatchNorm2d(8)\n",
        "        self.bn_2d_3 = torch.nn.BatchNorm2d(8)\n",
        "        self.bn_2d_4 = torch.nn.BatchNorm2d(64)\n",
        "        self.bn_2d_5 = torch.nn.BatchNorm2d(64)\n",
        "        self.bn_2d_6 = torch.nn.BatchNorm2d(64)\n",
        "        self.bn_2d_7 = torch.nn.BatchNorm2d(64)\n",
        "        self.bn_2d_8 = torch.nn.BatchNorm2d(8)\n",
        "        self.bn_2d_9 = torch.nn.BatchNorm2d(8)\n",
        "        self.bn_2d_10 = torch.nn.BatchNorm2d(8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn_2d_0(x)\n",
        "        x = self.ac1(self.con1(x))\n",
        "        x = self.bn_2d_1(x)\n",
        "        x = self.ac2(self.con2(x))\n",
        "        x = self.bn_2d_2(x)\n",
        "        x = self.ac3(self.con3(x))\n",
        "        x = self.bn_2d_3(x)\n",
        "        x = self.ac4(self.con4(x))\n",
        "        x = self.bn_2d_4(x)\n",
        "        x = self.ac5(self.con5(x))\n",
        "        x = self.bn_2d_5(x)\n",
        "        x = self.ac6(self.con6(x))\n",
        "        x = self.bn_2d_6(x)\n",
        "        x = self.ac7(self.con7(x))\n",
        "        x = self.bn_2d_7(x)\n",
        "        x = self.ac8(self.con8(x))\n",
        "        x = self.bn_2d_8(x)\n",
        "        x = self.ac9(self.con9(x))\n",
        "        x = self.bn_2d_9(x)\n",
        "        x = self.ac10(self.con10(x))\n",
        "        x = self.bn_2d_10(x)\n",
        "        x = self.ac11(self.con11(x))\n",
        "        return x;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l48etapcDWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = FaceNet(size)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "loss = torch.nn.MSELoss(reduction = 'sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3, amsgrad=True) #, momen)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLXpkjfJcFgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "print(device)\n",
        "model = train_model(model, loss, optimizer, scheduler, num_epochs=1, k=koef)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys5AMyBWPdOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), os.path.join(dir_name, \"model_best\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}